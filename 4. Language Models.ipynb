{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Языковые модели\n",
    "\n",
    "**Языковая модель** *(language model, LM)* позволяет оценить вероятность последовательности слов (токенов). \n",
    "\n",
    "$$P(W)=P\\left(w_{1}, w_{2}, w_{3}, \\dots, w_{n}\\right)$$\n",
    "\n",
    "Как следствие, с помощью языковой модели можно предсказать вероятность следующего слова в последовательности.\n",
    "\n",
    "$$P\\left(w_{5} | w_{1}, w_{2}, w_{3}, w_{4}\\right)$$\n",
    "\n",
    "\n",
    "Какая последовательность вероятнее? \n",
    "\n",
    "Поезд прибыл на\n",
    "* вокзал\n",
    "* север\n",
    "\n",
    "Какая последовательность вероятнее?\n",
    "* Вокзал прибыл поезд на\n",
    "* Поезд прибыл на вокзал\n",
    "\n",
    "### Применение\n",
    "\n",
    "* Генерация текста\n",
    "* Распознавание речи\n",
    "* OCR \n",
    "* Машинный перевод\n",
    "* Исправление опечаток\n",
    "* Определениt языка\n",
    "* Определение части речи (POS-tagging)\n",
    "* ...\n",
    "\n",
    "[Презентация Мурата Апишева](http://www.machinelearning.ru/wiki/images/5/5d/Mel_lain_msu_nlp_sem_2.pdf) с более подробными объяснениями и более сложными теоретическими вещами про языковые модели. Кое-что из этой презентации есть в теоретической части этой тетрадки.\n",
    "\n",
    "[Хороший тьюториал](https://towardsdatascience.com/learning-nlp-language-models-with-real-data-cdff04c51c25) по языковым моделям на *towardsdatascience*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Счетные языковые модели\n",
    "## Модель N-грамм\n",
    "\n",
    "Пусть $w_1,\\ldots,w_m$ – последовательность слов. Тогда вероятность данной последовательности можно оценить следующм образом (**цепное правило**):\n",
    "\n",
    "$$ P(w_{1}, \\ldots, w_{m})=\\prod_{i=1}^{m} P(w_{i} | w_{1}, \\ldots, w_{i-1}) \\approx \\prod_{i=1}^{m} P(w_{i} | w_{i-(n-1)}, \\ldots, w_{i-1}) $$\n",
    "\n",
    "### Марковское свойство n-ного порядка\n",
    "Запоминаем не всю цепочку, а только $n-1$ предшествующих слов. Тогда вероятностью i-того слова $w_i$ в контексте предшествущих $i − 1$ слов можно считать вероятность этого слова в сокращенном контексте предшествущих $n − 1$ слов.\n",
    "\n",
    "Модель\n",
    "* униграмм: $P(w_i)$\n",
    "* биграмм: $P(w_i | w_{i-1})$\n",
    "* триграмм: $P(w_i | w_{i-1} w_{i-2})$\n",
    "\n",
    "\n",
    "* Вероятность i-того слова в последовательности: $P(w_{i+1} | w_1, \\dots, w_i) \\approx P(w_{i-n}, \\dots, w_i)$\n",
    "* Вероятность всей последовательности слов: $P(w_1, \\dots, w_i) = \\prod_{i=1}^{m} P(w_i | w_{i-n+1}, \\dots, w_{i-1}) $\n",
    "\n",
    "\n",
    "### Метод максимального правдоподобия \n",
    "\n",
    "ММП оценки вероятностей (*Maximum likelihood estimate, MLE*)\n",
    "\n",
    "$ P(w_{i} | w_{i-(n-1)}, \\ldots, w_{i-1})=\\frac{\\operatorname{count}(w_{i-(n-1)}, \\ldots, w_{i-1}, w_{i})}{\\operatorname{count}(w_{i-(n-1)}, \\ldots, w_{i-1})} $\n",
    "\n",
    "В модели биграмм:\n",
    "\n",
    "$P_{MLE}(w_k | w_{k-1}) = \\frac{\\texttt{count}(w_{k-1} w_k )}{\\texttt{count}(w_{k-1} )}$\n",
    "\n",
    "### Сглаживание\n",
    "\n",
    "#### Зачем?\n",
    "* Огранниченность корпуса\n",
    "* Занижена вероятность\n",
    "* Вероятность равна нулю\n",
    "\n",
    "### Методы\n",
    "* Сглаживание Лапласа (add-one)\n",
    "* Сглаживание Кнесера-Нея (Kneser-Ney)\n",
    "* Сглаживание Виттена-Белла (Witten-Bell)\n",
    "* Сглаживание Гуда-Тьюринга (Good-Turing)\n",
    "* Интерполяция\n",
    "* Откат (backoff)\n",
    "\n",
    "### Аддитивное сглаживание Лапласа\n",
    "\n",
    "Просто добавляем 1 к встречаемости каждой N-граммы.\n",
    "\n",
    "$ P(w_k | w_{k-1}) = \\frac{\\texttt{count}(w_{k-1} w_k ) + \\alpha}{\\texttt{count}(w_{k-1} ) + \\alpha |V|} $\n",
    "\n",
    "$|V|$ — размер словаря\n",
    "\n",
    "### Откат \n",
    "\n",
    "**Katz smoothing** (простой откат): если не получается применить модель высокого порядка, пробуем для данного слова модель меньшего порядка с понижающим множителем. \n",
    "\n",
    "Но получим не вероятностное распределение!\n",
    "\n",
    "\n",
    "### Качество модели  $n$-грамм\n",
    "\n",
    "**Перплексия** — насколько хорошо модель предсказывает выборку. Чем ниже значение перплексии, тем лучше.\n",
    "\n",
    "$PP(\\texttt{LM}) = b^{{-{\\frac  {1}{N}}\\sum _{{i=1}}^{N}\\log _{b}\\texttt{LM}(x_{i})}}$,\n",
    "\n",
    "$N$ — длина корпуса<br>$x_i$ — i-тое слово в корпусе<br>LM(x) — предсказание вероятности языковой моделью<br>b — некоторая константа, обычно 2\n",
    "\n",
    "### Модель униграмм (модель мешка слов)\n",
    "\n",
    "В такой модели вероятность слова в последовательности зависит исключительно от вероятности этого слова в корпусе, т.е. контекст не учитывается.\n",
    "\n",
    "$ P(w_{1}, \\ldots, w_{n}) \\approx \\prod_{i} P(w_{i}w_{i-2}) $\n",
    "\n",
    "### Модель биграмм\n",
    "\n",
    "Каждое слово зависит от одного предыдущего слова.\n",
    "\n",
    "$ P\\left(w_{i} | w_{1} w_{2}, \\ldots w_{i}-1\\right) \\approx P\\left(w_{i} | w_{i-1}\\right) $\n",
    "\n",
    "### Модель триграмм\n",
    "\n",
    "Каждое слово зависит от двух предыдущих слов.\n",
    "\n",
    "$P\\left(w_{i} | w_{1} w_{2}, \\ldots w_{i}-1\\right) \\approx P\\left(w_{i} | w_{i-1}\\right)$\n",
    "\n",
    "## Модели N-грамм в NLTK\n",
    "\n",
    "Вероятностные распределения в NLTK: https://www.nltk.org/_modules/nltk/probability.html\n",
    "\n",
    "<img src=\"./img/freqdist.png\" width=\"700\" align=\"left\">\n",
    "\n",
    "<img src=\"./img/condfreqdist.png\" width=\"800\" align=\"left\">\n",
    "\n",
    "<img src=\"./img/condfreqdist2.png\" width=\"750\" align=\"left\">\n",
    "\n",
    "<img src=\"./img/mleprobdist.png\" width=\"750\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aachenosaurus',\n",
       " 'aardonyx',\n",
       " 'abdallahsaurus',\n",
       " 'abelisaurus',\n",
       " 'abrictosaurus',\n",
       " 'abrosaurus',\n",
       " 'abydosaurus',\n",
       " 'acanthopholis',\n",
       " 'achelousaurus',\n",
       " 'acheroraptor']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import FreqDist, ConditionalFreqDist, ConditionalProbDist, MLEProbDist\n",
    "from nltk import bigrams, trigrams\n",
    "\n",
    "with open('./data/dinos.txt', 'r', encoding='utf-8') as f:\n",
    "    data = f.readlines()\n",
    "names = [name.strip().lower() for name in data]\n",
    "names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'c', 'h', 'e', 'n', 'o', 's', 'u', 'r', 'd', 'y', 'x', 'b', 'l', 'i', 't', 'p', 'v', 'm', 'g', 'f', 'j', 'k', 'w', 'z', 'q']\n"
     ]
    }
   ],
   "source": [
    "chars = [char  for name in names for char in name]\n",
    "freq = FreqDist(chars)\n",
    "\n",
    "print(list(freq.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 26 samples and 2487 outcomes>\n"
     ]
    }
   ],
   "source": [
    "cfreq = ConditionalFreqDist(bigrams(chars))\n",
    "print(cfreq['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(a a) = 0.0105\n",
      "p(a b) = 0.0129\n",
      "p(a u) = 0.3185\n"
     ]
    }
   ],
   "source": [
    "cprob = ConditionalProbDist(cfreq,MLEProbDist)\n",
    "print('p(a a) = %1.4f' %cprob['a'].prob('a'))\n",
    "print('p(a b) = %1.4f' %cprob['a'].prob('b'))\n",
    "print('p(a u) = %1.4f' %cprob['a'].prob('u'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(a) = 0.1354\n"
     ]
    }
   ],
   "source": [
    "l = sum([freq[char] for char in freq])\n",
    "\n",
    "def unigram_prob(char):\n",
    "    return freq[char] / l\n",
    "\n",
    "print('p(a) = %1.4f' %unigram_prob('a'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно порождать случайные символы с учётом предыдущих."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cprob['a'].generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание №1\n",
    "\n",
    "1. Напишите функцию для генерации нового имени динозавра фиксированной длины.\n",
    "2. Обучите модель триграмм на данных любой газеты (например, \"Полярный круг\", которая выложена в папке data). Какой корпус понадобится: лемматизированный или нет? Понадобится ли пунктуация?\n",
    "3. Напишите функцию, которая будет оценивать вероятность следующего слова для данной последовательности и функцию, которая будет предсказывать самое вероятное следующее слово для данной последовательности. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нейросетевые модели\n",
    "\n",
    "## Рекуррентные нейронные языковые модели\n",
    "\n",
    "RNN позволяют уйти от Марковских допущений и позволяют учитывать предысторию произвольной длины.\n",
    "\n",
    "$x_{1:n} = x_1, x_2, \\ldots, x_n$, $x_i \\in \\mathbb{R}^{d_{in}}$\n",
    "\n",
    "$y_n = RNN(x_{1:n})$, $y_n \\in \\mathbb{R}^{d_{out}}$\n",
    "\n",
    "Для каждого префикса $x_{i:i}$ $y_i$ – выходной вектор.\n",
    "\n",
    "$y_i = RNN(x_{1:i})$\n",
    "\n",
    "$y_{1:n} = RNN^{*}(x_{1:n})$, $y_i \\in \\mathbb{R}^{d_{out}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$R$ –  рекурсивная функция с двумя входами: $x_i$ и $s_{i-1}$ (вектор состояния)\n",
    "\n",
    "$RNN^{*}(x_{1:n}, s_0) = y_{1:n}$\n",
    "\n",
    "$y_i = O(s_i)$\n",
    "\n",
    "$s_i = R(s_{i-1}, x_i)$\n",
    "\n",
    "$s_i = R(s_{i-1}, x_i) = g(s_{i-1}* W^s + x_i W^x +b)$\n",
    "\n",
    "$x_i \\in \\mathbb{R}^{d_{in}}$, $y_i \\in \\mathbb{R}^{d_{out}}$, $s_i \\in \\mathbb{R}^{d_{out}}$\n",
    "\n",
    "$W^x \\in \\mathbb{R}^{d_{in} \\times d_{in}}$, $W^s \\in \\mathbb{R}^{d_{out} \\times d_{out}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![rnn](img/rnn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pdb\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "torch.set_printoptions(linewidth=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "hidden_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DinosDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        with open('./data/dinos.txt') as f:\n",
    "            content = f.read().lower()\n",
    "            self.vocab = sorted(set(content))\n",
    "            self.vocab_size = len(self.vocab)\n",
    "            self.lines = content.splitlines()\n",
    "        self.ch_to_idx = {c:i for i, c in enumerate(self.vocab)}\n",
    "        self.idx_to_ch = {i:c for i, c in enumerate(self.vocab)}\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        line = self.lines[index]\n",
    "        #teacher forcing\n",
    "        x_str = line\n",
    "        y_str = line[1:] + '\\n'\n",
    "        x = torch.zeros([len(x_str), self.vocab_size], dtype=torch.float)\n",
    "        y = torch.empty(len(x_str), dtype=torch.long)\n",
    "        for i, (x_ch, y_ch) in enumerate(zip(x_str, y_str)):\n",
    "            x[i][self.ch_to_idx[x_ch]] = 1\n",
    "            y[i] = self.ch_to_idx[y_ch]\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = DinosDataset()\n",
    "trn_dl = DataLoader(trn_ds, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aardonyx\n"
     ]
    }
   ],
   "source": [
    "print(trn_ds.lines[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n"
     ]
    }
   ],
   "source": [
    "print(trn_ds.ch_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]])\n",
      "tensor([ 1, 18,  4, 15, 14, 25, 24,  0])\n"
     ]
    }
   ],
   "source": [
    "x, y = trn_ds[1]\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![rnn](img/dinos3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, h_prev, x):\n",
    "        combined = torch.cat([h_prev, x], dim = 1) # конкатенируем вектора состояния и входа\n",
    "        h = torch.tanh(self.dropout(self.i2h(combined)))\n",
    "        y = self.i2o(combined)\n",
    "        return h, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(trn_ds.vocab_size, hidden_size, trn_ds.vocab_size).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sample(sample_idxs):\n",
    "    [print(trn_ds.idx_to_ch[x], end='') for x in sample_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(model):\n",
    "    model.eval()\n",
    "    word_size=0\n",
    "    newline_idx = trn_ds.ch_to_idx['\\n']\n",
    "    with torch.no_grad():\n",
    "        h_prev = torch.zeros([1, hidden_size], dtype=torch.float, device=device)\n",
    "        x = h_prev.new_zeros([1, trn_ds.vocab_size])\n",
    "        start_char_idx = random.randint(1, trn_ds.vocab_size-1)\n",
    "        indices = [start_char_idx]\n",
    "        x[0, start_char_idx] = 1\n",
    "        predicted_char_idx = start_char_idx\n",
    "        \n",
    "        while predicted_char_idx != newline_idx and word_size != 50:\n",
    "            h_prev, y_pred = model(h_prev, x)\n",
    "            y_softmax_scores = torch.softmax(y_pred, dim=1)\n",
    "            \n",
    "            np.random.seed(np.random.randint(1, 5000))\n",
    "            idx = np.random.choice(np.arange(trn_ds.vocab_size), p=y_softmax_scores.cpu().numpy().ravel())\n",
    "            indices.append(idx)\n",
    "            \n",
    "            x = (y_pred == y_pred.max(1)[0]).float()\n",
    "            predicted_char_idx = idx\n",
    "            \n",
    "            word_size += 1\n",
    "        \n",
    "        if word_size == 50:\n",
    "            indices.append(newline_idx)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    for line_num, (x, y) in enumerate(trn_dl):\n",
    "        loss = 0\n",
    "        optimizer.zero_grad()\n",
    "        h_prev = torch.zeros([1, hidden_size], dtype=torch.float, device=device)\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        for i in range(x.shape[1]):\n",
    "            h_prev, y_pred = model(h_prev, x[:, i])\n",
    "            loss += loss_fn(y_pred, y[:, i])\n",
    "            \n",
    "        if (line_num+1) % 100 == 0:\n",
    "            print_sample(sample(model))\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, optimizer, dataset='dinos', epochs=1):\n",
    "    for e in range(1, epochs+1):\n",
    "        print('Epoch:{}'.format(e))\n",
    "        train_one_epoch(model, loss_fn, optimizer)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1\n",
      "zlorya\n",
      "gepaic\n",
      "ttxas\n",
      "rbpanrus\n",
      "lftagaoaurusuusus\n",
      "rcterauhus\n",
      "lwscnrus\n",
      "bblrbaurus\n",
      "elcltvaurus\n",
      "mtlianhrus\n",
      "pbtrsllhurus\n",
      "krstaauius\n",
      "brltaauras\n",
      "mtlhbmcrus\n",
      "jasrsanrusaurus\n",
      "\n",
      "Epoch:2\n",
      "mamiahraeurls\n",
      "onanesaurus\n",
      "nyrreoshurus\n",
      "vytiosncrur\n",
      "osashsalruc\n",
      "ldtgmcglrus\n",
      "harssaurus\n",
      "uslsouaus\n",
      "qgsaonocrus\n",
      "zkhtlnaumus\n",
      "gucsrsaurusaurusaaroe\n",
      "esatisa\n",
      "zsnaohiuros\n",
      "qivoudssaurus\n",
      "cyrmrsoarur\n",
      "\n",
      "Epoch:3\n",
      "ytbpisaurui\n",
      "yctgmcglrus\n",
      "xastsaurus\n",
      "osgrruagna\n",
      "qtboisauruc\n",
      "taranasaurus\n",
      "qttolkoppturus\n",
      "yaniangurus\n",
      "iarianaurus\n",
      "danwosaurus\n",
      "ornnuoraurds\n",
      "jacsasaurus\n",
      "jalgsnacras\n",
      "goudrseurus\n",
      "pyrjriuaus\n",
      "\n",
      "Epoch:4\n",
      "ngsaurua\n",
      "zrnaraurum\n",
      "hamyrolrus\n",
      "oiosttsistoc\n",
      "chabtataunus\n",
      "mamgsaunus\n",
      "yxnteskurus\n",
      "urytsosncrus\n",
      "drcsisaurua\n",
      "fetgicierus\n",
      "lasosnaurus\n",
      "nisosapaurus\n",
      "gfuaasabrus\n",
      "xiarbnsurus\n",
      "zsngosaurus\n",
      "\n",
      "Epoch:5\n",
      "buaisauris\n",
      "euadopalhor\n",
      "varasrrudtos\n",
      "uluscysus\n",
      "xuanicaurus\n",
      "iaeoobaurus\n",
      "gtbiusourus\n",
      "jenniuaurus\n",
      "anranlerus\n",
      "papmbanrus\n",
      "xsanuosaurus\n",
      "shurusaurur\n",
      "wicgschuris\n",
      "chachopl\n",
      "yucgxrnurus\n",
      "\n",
      "Epoch:6\n",
      "tesooturus\n",
      "vamichs\n",
      "voltcerl\n",
      "epathnasaurus\n",
      "drroniosaurus\n",
      "wubgocgsaurus\n",
      "runaodourus\n",
      "ansosaurus\n",
      "zrriysisns\n",
      "ongchsaurus\n",
      "monapaurus\n",
      "famuosdsiurus\n",
      "eoytospucus\n",
      "elrcontcrus\n",
      "epatioaurus\n",
      "\n",
      "Epoch:7\n",
      "fuioseurus\n",
      "lxrhnsrcaurus\n",
      "grltahauhus\n",
      "jibcoantssurus\n",
      "zepooyoistu\n",
      "henbfsaurus\n",
      "qulamgourus\n",
      "kiviugossaurus\n",
      "vqnntpcaurus\n",
      "aurucauras\n",
      "drngasaurus\n",
      "nrtiicsosuurus\n",
      "eagpappcsaujus\n",
      "dandsaurus\n",
      "utotgossaurus\n",
      "\n",
      "Epoch:8\n",
      "sinrus\n",
      "fin\n",
      "elpcrnrcauras\n",
      "sinrasaurus\n",
      "kutponoosuurus\n",
      "bamecaurus\n",
      "nabrncaurus\n",
      "rubsrsturus\n",
      "olostus\n",
      "cirpbopaaurus\n",
      "hadpiaideuros\n",
      "veuotaurus\n",
      "morhysosaurus\n",
      "iatarnt\n",
      "jannanliurus\n",
      "\n",
      "Epoch:9\n",
      "phtosaurus\n",
      "orootoriutai\n",
      "aapuccurus\n",
      "araoltrris\n",
      "kitiucsourus\n",
      "urysaurus\n",
      "jianoasaurus\n",
      "uanettras\n",
      "yltntcosei\n",
      "ckrcyopsaucus\n",
      "waoaolt\n",
      "garoapesaurus\n",
      "quntcsopsaurus\n",
      "glrovang\n",
      "omocths\n",
      "\n",
      "Epoch:10\n",
      "gasgasaurus\n",
      "carwtrnsstis\n",
      "monyoraures\n",
      "naeocgurms\n",
      "gnaihsaurus\n",
      "dvntcsusaurus\n",
      "runtos\n",
      "venalocootar\n",
      "gmajhsnalrus\n",
      "wiucssneisshut\n",
      "gostanakrus\n",
      "betaetocamtss\n",
      "auciscurus\n",
      "urespntusauris\n",
      "valocoocerus\n",
      "\n",
      "Epoch:11\n",
      "hiksgnao\n",
      "eoyprestus\n",
      "xlnnysnors\n",
      "kinaisarntirus\n",
      "yoerknasaurus\n",
      "nrtoristotuntouaaurus\n",
      "queuaatiasaurus\n",
      "jaitiuhdurus\n",
      "urixturus\n",
      "tgoaisaurus\n",
      "lonammgores\n",
      "dotnxhoosaurus\n",
      "prlotsbaurus\n",
      "prltaliuius\n",
      "ngjaxdotaurus\n",
      "\n",
      "Epoch:12\n",
      "zilsosturus\n",
      "saoraseurus\n",
      "hapgancrnanrus\n",
      "frsatssaurus\n",
      "sirrosaurus\n",
      "marescashangonaurus\n",
      "lotgrsoonaurus\n",
      "cirscaurus\n",
      "tonrcersaurus\n",
      "absarturus\n",
      "irngrsaurus\n",
      "wubipauros\n",
      "drcdrnaonhuros\n",
      "thvovaurus\n",
      "rosnysaurus\n",
      "\n",
      "Epoch:13\n",
      "xianoasaurus\n",
      "a\n",
      "zilspacrus\n",
      "oructsaurus\n",
      "suurostcrus\n",
      "drcsbtaasacrus\n",
      "dictantluaurus\n",
      "jonnysrauras\n",
      "tanrcluros\n",
      "fnaoeturis\n",
      "litlycroosaurus\n",
      "ilnosaraurus\n",
      "eluberobaurus\n",
      "juanyouiourus\n",
      "vinytisaurus\n",
      "\n",
      "Epoch:14\n",
      "zetataurus\n",
      "zancsaurus\n",
      "surshssurus\n",
      "xixngoso\n",
      "onichudaus\n",
      "kasiaiasaurus\n",
      "vuntgrsoptor\n",
      "kysesotagncat\n",
      "silramounus\n",
      "tenascgusaurus\n",
      "olopoysoulu\n",
      "anrantcrus\n",
      "fcsiajmaurus\n",
      "kiviucsaurus\n",
      "zhxspauras\n",
      "\n",
      "Epoch:15\n",
      "kaloasaurus\n",
      "uamftrris\n",
      "ikuoudaurus\n",
      "shntosauros\n",
      "uaisaurus\n",
      "irnaonoisaurus\n",
      "juansoianoovdurus\n",
      "kinamochurus\n",
      "ur\n",
      "xiangickapturus\n",
      "cooatossurus\n",
      "jaanagraoniurus\n",
      "foeuclas\n",
      "weuluddurus\n",
      "humyuqhuros\n",
      "\n",
      "Epoch:16\n",
      "daloasguan\n",
      "jiandungaturus\n",
      "kasttopaurus\n",
      "nottaoraurus\n",
      "euacoeasaurus\n",
      "banxstsrus\n",
      "lepnivoshurus\n",
      "tantasaurus\n",
      "bancsaurus\n",
      "ctitespurus\n",
      "savrriuros\n",
      "ocasasaurus\n",
      "wanetngasaurus\n",
      "xlsniisneupurus\n",
      "dlnabtataurus\n",
      "\n",
      "Epoch:17\n",
      "uajqtun\n",
      "aubisosaurus\n",
      "atritourus\n",
      "welalrdauros\n",
      "mibhesipaorox\n",
      "ptdttoraurus\n",
      "xinnyacnaurus\n",
      "bucashapaurus\n",
      "rantosaurus\n",
      "jrnnzunauris\n",
      "calocaurus\n",
      "ribohsaurus\n",
      "nyntasotgosaurus\n",
      "losaenanaurus\n",
      "iaslcaurus\n",
      "\n",
      "Epoch:18\n",
      "zudgtaurus\n",
      "thmmorturus\n",
      "eahnaesaosr\n",
      "xconaonoalaurus\n",
      "ructosaurus\n",
      "xolnsucaurus\n",
      "fukuahos\n",
      "xiatghaaorus\n",
      "verotodaurus\n",
      "moruaricaurus\n",
      "ecathalep\n",
      "qiasaiuntashurus\n",
      "kiyooouras\n",
      "qaenasauaesacrus\n",
      "mectbnyspurus\n",
      "\n",
      "Epoch:19\n",
      "ulusaurus\n",
      "osantanaes\n",
      "wucctnaurus\n",
      "qasgiuaurus\n",
      "hikponysaurus\n",
      "thcesataurus\n",
      "raneorectesaus\n",
      "fususaurus\n",
      "wenpucgk\n",
      "lepeonoerus\n",
      "hiismnathaurus\n",
      "xonngrtgusaurus\n",
      "opamtsrus\n",
      "ncslceurus\n",
      "iscguaurus\n",
      "\n",
      "Epoch:20\n",
      "weloonuurus\n",
      "falnaaurus\n",
      "ladricideurus\n",
      "heviydqtor\n",
      "drrgysgosagrus\n",
      "auburtcrus\n",
      "foeuiaerosaus\n",
      "rttonasaurus\n",
      "prraonaleurus\n",
      "fesibjgauros\n",
      "nixlsasturus\n",
      "eoyshrltaor\n",
      "amsasaurus\n",
      "uajitroasaurus\n",
      "hutsemsus\n",
      "\n",
      "Epoch:21\n",
      "gsnhuras\n",
      "ocephops\n",
      "markandolalros\n",
      "kosastsaurus\n",
      "psnntocrud\n",
      "wseogtcrus\n",
      "klhuniasaurus\n",
      "nstoalosnturus\n",
      "galganoasaurus\n",
      "sanfsaurus\n",
      "ptnueosaurus\n",
      "eytposscrus\n",
      "aubusterus\n",
      "weltinaubaurus\n",
      "junngosgvurast\n",
      "\n",
      "Epoch:22\n",
      "iinaraurus\n",
      "laphanesaurus\n",
      "eumuesotsaurus\n",
      "ilnotauras\n",
      "fasauaasacrus\n",
      "enataiusoeaurus\n",
      "cinytorsxaor\n",
      "ngtargtaurun\n",
      "yesnpaurus\n",
      "crlotopaurus\n",
      "xinnnanamrus\n",
      "vesacopatops\n",
      "harbotltasaurus\n",
      "vexookurus\n",
      "ocgsaurus\n",
      "\n",
      "Epoch:23\n",
      "zrhaidsaurus\n",
      "hynvdsoosaurus\n",
      "yprouaragauaurus\n",
      "grnanneurus\n",
      "sauosaurus\n",
      "brrhytisaurus\n",
      "xinasntdauros\n",
      "lrhhasaurus\n",
      "xirnggskltaurus\n",
      "henchsarpturus\n",
      "apcuraerus\n",
      "yrtasaurus\n",
      "jiyngosecrus\n",
      "prctiscauras\n",
      "pslecochyntisltolaurus\n",
      "\n",
      "Epoch:24\n",
      "xinnasilauius\n",
      "waloicaurus\n",
      "osaithodeurus\n",
      "ronwopsstas\n",
      "uahsaurup\n",
      "xinajaogsaurus\n",
      "usasturus\n",
      "nixolirs\n",
      "glnagiprus\n",
      "lbpharaurus\n",
      "lantosdspurus\n",
      "wextnoshlrus\n",
      "sicrosaurus\n",
      "saugocoirus\n",
      "desrongosaurus\n",
      "\n",
      "Epoch:25\n",
      "quaih\n",
      "onocturas\n",
      "bibihkuras\n",
      "wdultaurus\n",
      "clonysaurus\n",
      "zhceudiisaurui\n",
      "xepngasalur\n",
      "jbonnoniurus\n",
      "wlnuang\n",
      "eltbopeirus\n",
      "velonkchurus\n",
      "zaurillnosturus\n",
      "uainaurus\n",
      "quallncaurus\n",
      "wudguro\n",
      "\n",
      "Epoch:26\n",
      "brtnncsaurus\n",
      "qusdlraurus\n",
      "xramgoagataurus\n",
      "hyptesturus\n",
      "thxunosoc\n",
      "jianiauasamgurus\n",
      "ceectansls\n",
      "nttoomosaurus\n",
      "vucipaurus\n",
      "stbconakieurus\n",
      "iluosaurus\n",
      "norovrritohs\n",
      "uags\n",
      "viltceracops\n",
      "ylasasourus\n",
      "\n",
      "Epoch:27\n",
      "wrleosaurus\n",
      "bubgnaas\n",
      "quetaasacrus\n",
      "ylasdotaurus\n",
      "ypaptotuptor\n",
      "phlakociurus\n",
      "webhhsgidaurus\n",
      "tatturaurus\n",
      "ripsocmpais\n",
      "zreqdasnco\n",
      "gtjgauaotaurus\n",
      "fpgurhtopsus\n",
      "velagodaurus\n",
      "mibhesgnaurus\n",
      "aucqshurus\n",
      "\n",
      "Epoch:28\n",
      "kysetoraaurus\n",
      "brlsceos\n",
      "jiangiaseosaurus\n",
      "epbtopysaurus\n",
      "qoansaseoaauras\n",
      "coencodgtsiurus\n",
      "beronysaurus\n",
      "kiaescsaurus\n",
      "yangunarrus\n",
      "houdsaurus\n",
      "zhyrgosoasaurus\n",
      "qiscgonapernaas\n",
      "meuptaurus\n",
      "virivturus\n",
      "onicaurus\n",
      "\n",
      "Epoch:29\n",
      "racooaaurus\n",
      "etasrsturus\n",
      "gfpinyaurus\n",
      "kinalsas\n",
      "us\n",
      "bargbnngurus\n",
      "weuiudoosaurus\n",
      "gunirsainaurus\n",
      "lubeon\n",
      "weltipaurus\n",
      "itdttsgaonausaurur\n",
      "vedataran\n",
      "veriboniurus\n",
      "zhynsarosaurus\n",
      "monposapaurus\n",
      "\n",
      "Epoch:30\n",
      "ngtacsua\n",
      "okoiahrus\n",
      "oructsotoss\n",
      "ovontot\n",
      "ximahiurus\n",
      "fernaalrus\n",
      "xlanysturus\n",
      "qirngusaurun\n",
      "kiaasasaurus\n",
      "walcsgraurus\n",
      "sthtrsaurus\n",
      "trrrosapalrus\n",
      "tetaasg\n",
      "tiksnnaurus\n",
      "kucotosaurus\n",
      "\n",
      "Epoch:31\n",
      "urostcrus\n",
      "usatgtdaurus\n",
      "mohgasaptsu\n",
      "siuronaurus\n",
      "fusubosaurus\n",
      "wucconannaurus\n",
      "phtouisturus\n",
      "ilusornsaor\n",
      "ylsgrnt\n",
      "ogopaurus\n",
      "paraktsturus\n",
      "elorotipturus\n",
      "zaepeioirrus\n",
      "ypctjjaurus\n",
      "wulsurnasausausau\n",
      "\n",
      "Epoch:32\n",
      "hencsaurus\n",
      "tatgarashoiu\n",
      "qmwnuasosaurus\n",
      "conhtocl\n",
      "edatasesauruk\n",
      "xesjharatrps\n",
      "grspinaurus\n",
      "lorparaorus\n",
      "tetaisacrus\n",
      "becrbqups\n",
      "nttoraurus\n",
      "ripttanasrus\n",
      "kesagopanaugoa\n",
      "canttomaurus\n",
      "ksnysoyspcrus\n",
      "\n",
      "Epoch:33\n",
      "vneoct\n",
      "fesaangtaurus\n",
      "xunndruus\n",
      "usunuurus\n",
      "kanacosaoptmrus\n",
      "weltnacrus\n",
      "ziuciosgisaurus\n",
      "brtalidaurus\n",
      "abcoraurus\n",
      "zauahyoyesiurus\n",
      "beytiottarus\n",
      "yuanevatrua\n",
      "iaugnchurus\n",
      "veroshenrosaurus\n",
      "flracsasaurus\n",
      "\n",
      "Epoch:34\n",
      "jangsnraurus\n",
      "auctstengtotsisos\n",
      "flo\n",
      "besasaurus\n",
      "iandsaurus\n",
      "kurucosaurus\n",
      "kwsarosauris\n",
      "bateuasrua\n",
      "lephocochusus\n",
      "ususaurut\n",
      "pintuanadrus\n",
      "ceycguacros\n",
      "igcslaurus\n",
      "trtoisaurus\n",
      "totaonajsaurus\n",
      "\n",
      "Epoch:35\n",
      "zrnahitis\n",
      "quanyoudosotrqunuurus\n",
      "kalbcgsaurus\n",
      "vilapaurus\n",
      "xactqtassosaurus\n",
      "epmtoccurus\n",
      "juanaasg\n",
      "piktnicaurus\n",
      "kastnngosaurus\n",
      "crdirapeurus\n",
      "kaseanarathr\n",
      "chtitorsiurus\n",
      "hyroauoasasrus\n",
      "vetados\n",
      "xianggdsasnurus\n",
      "\n",
      "Epoch:36\n",
      "zrocoraurps\n",
      "trcgicaurus\n",
      "racorapeor\n",
      "jaohgursmaurus\n",
      "molyooscurus\n",
      "kesatis\n",
      "xannamaurus\n",
      "xacsitaurus\n",
      "roshysoshurus\n",
      "idsconscaurus\n",
      "gtlgasaurus\n",
      "loshineurus\n",
      "fusyani\n",
      "vepatosaurus\n",
      "ndtinaurus\n",
      "\n",
      "Epoch:37\n",
      "usaspurus\n",
      "zhysiosoerus\n",
      "grbsnrdauros\n",
      "juanataurus\n",
      "vironaroptus\n",
      "brtamnabsaurus\n",
      "esiaolsraurus\n",
      "potatosaurus\n",
      "fultuocaurus\n",
      "quctcaukan\n",
      "pslacrdaurus\n",
      "wunnaurus\n",
      "gnomubgnlaurus\n",
      "bahoraurus\n",
      "fasaiuurus\n",
      "\n",
      "Epoch:38\n",
      "xingpiusus\n",
      "lopaonapmurus\n",
      "paoe\n",
      "biirmiclrrus\n",
      "agrussasaurus\n",
      "esuaoranter\n",
      "euacorators\n",
      "acsastisaurus\n",
      "ropivpsauras\n",
      "saltaonperus\n",
      "tigoil\n",
      "xianzotfoosaurus\n",
      "ltniosapharu\n",
      "wrltaeinahoeha\n",
      "xianzotataurus\n",
      "\n",
      "Epoch:39\n",
      "jiyois\n",
      "quaniamasrus\n",
      "jennaohaurus\n",
      "glvpvasostor\n",
      "biypnosierus\n",
      "drcodoc\n",
      "brraoiiurus\n",
      "rivlydoshurus\n",
      "purirotagnaures\n",
      "kuaatmbiltor\n",
      "socitryarssoastou\n",
      "gnrpuaisaurus\n",
      "gubduraphor\n",
      "iatansurus\n",
      "eslcirovaurus\n",
      "\n",
      "Epoch:40\n",
      "phnahsaurus\n",
      "wrnabnqsaurus\n",
      "potcyrpnaosaurus\n",
      "auairanter\n",
      "fuaaur\n",
      "aqcunbcrus\n",
      "saurotaurus\n",
      "fvshtsucaurus\n",
      "quesaceulus\n",
      "xicgxaaurus\n",
      "brtemosaurus\n",
      "crdatfpsaurus\n",
      "junagisgkaurus\n",
      "bufottnaurus\n",
      "riptrcaurus\n",
      "\n",
      "Epoch:41\n",
      "fuluaaurus\n",
      "hulidourus\n",
      "vertthasontureuras\n",
      "fakubois\n",
      "agsoaarros\n",
      "quanyosaurus\n",
      "irngxs\n",
      "ciusaonaas\n",
      "esetadopaor\n",
      "uriaterusaos\n",
      "drngrsgwsnsiukus\n",
      "unuaopokops\n",
      "ligsenasaurus\n",
      "kusrhersaurus\n",
      "kuaeccisaurus\n",
      "\n",
      "Epoch:42\n",
      "fur\n",
      "imethectlrus\n",
      "kasuonisaurus\n",
      "nstbhocaurus\n",
      "kaitnasaurus\n",
      "yanypsaurus\n",
      "clriuosauras\n",
      "qacrdont\n",
      "pardarcs\n",
      "libranusourus\n",
      "keskcusshus\n",
      "cemarodauris\n",
      "xiancsanrus\n",
      "burueosaurus\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gyroospcrus\n",
      "\n",
      "Epoch:43\n",
      "rucontgrus\n",
      "piktmr\n",
      "ntcososeots\n",
      "jinorturus\n",
      "hamlcaurus\n",
      "dacpnaonhurus\n",
      "hevoogostor\n",
      "nokysaurus\n",
      "vecesaravaar\n",
      "namnqhnaurus\n",
      "kuittosaurus\n",
      "nitoucosaurus\n",
      "bucatacrus\n",
      "ylasantosaurus\n",
      "usoiviurus\n",
      "\n",
      "Epoch:44\n",
      "ceparoguptdr\n",
      "sabmcorapops\n",
      "gosgsshurus\n",
      "vuritorantir\n",
      "nasaucasacrus\n",
      "dicoantsourus\n",
      "tetjnvosaurus\n",
      "galoaoes\n",
      "saroaonoahauasuurus\n",
      "yunhshurus\n",
      "irtaonaisaurus\n",
      "wrlaeootops\n",
      "beuiucsaurus\n",
      "ilutsaurus\n",
      "tamoasaurus\n",
      "\n",
      "Epoch:45\n",
      "uaoriur\n",
      "osamtntpaurus\n",
      "krnyongot\n",
      "glnahsaurus\n",
      "usiangsaurus\n",
      "dyptatqsaurus\n",
      "ntnoruasaurus\n",
      "jirggoqaichurus\n",
      "betntespurus\n",
      "glypnouter\n",
      "dalpcosmcrus\n",
      "kilolhesaurus\n",
      "qurnldosgys\n",
      "vintcor\n",
      "perasguaauras\n",
      "\n",
      "Epoch:46\n",
      "etaiasa\n",
      "ustt\n",
      "fustthsaurus\n",
      "visanenrus\n",
      "wapaesgbaurus\n",
      "tregusourus\n",
      "hapsovkurus\n",
      "ginalsas\n",
      "mtcdsacrus\n",
      "onasaurus\n",
      "nttrnerntrps\n",
      "drsamgang\n",
      "hulwaang\n",
      "pietelashos\n",
      "euatosaurus\n",
      "\n",
      "Epoch:47\n",
      "runtos\n",
      "rhnblsasipad\n",
      "xiangong\n",
      "qualurourus\n",
      "ceoonvoratops\n",
      "palocolosrus\n",
      "rictopaurus\n",
      "wuksrsaurus\n",
      "esitrrapter\n",
      "zaucodatods\n",
      "queicrdguit\n",
      "ososaurus\n",
      "juannucg\n",
      "paltcrnpfrus\n",
      "qucripaurus\n",
      "\n",
      "Epoch:48\n",
      "rucousaurus\n",
      "kurjtoaracrus\n",
      "onoanio\n",
      "epatnravaos\n",
      "vulotropaurus\n",
      "huptanras\n",
      "waneuaauras\n",
      "etedasasturus\n",
      "vinatoryurus\n",
      "tanhantauoud\n",
      "quhcomiurus\n",
      "zhynyasorianossurus\n",
      "palackourus\n",
      "pard\n",
      "opcoshesa\n",
      "\n",
      "Epoch:49\n",
      "usus\n",
      "rstoicseurus\n",
      "zoubgjdgsaurus\n",
      "nrmbgasgibaorus\n",
      "saurunaurus\n",
      "zhonoang\n",
      "cerasaurus\n",
      "rameyinasaurus\n",
      "usuongsaurus\n",
      "kutaoraurus\n",
      "ssccinbopaurus\n",
      "rivtrdosteryx\n",
      "tythoso\n",
      "thpaloceurus\n",
      "chacmorakrus\n",
      "\n",
      "Epoch:50\n",
      "saucsnurus\n",
      "anturtos\n",
      "nimadscrus\n",
      "nctnariiuras\n",
      "vetluesaurus\n",
      "xixngrso\n",
      "flnaasasaurus\n",
      "yahntodapa\n",
      "zuosgorosaurus\n",
      "hipoochol\n",
      "drcsdrc\n",
      "aurapaoooc\n",
      "uaiskurus\n",
      "weloroteurus\n",
      "velarpcrus\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time train(model, loss_fn, optimizer, epochs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание №2\n",
    "Измените код выше так, чтобы генерировались панграммы – имена динозавров, не содержащие повторяющихся букв."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Использование LSTM нейронов\n",
    "\n",
    "![rnn](img/LSTM_rnn.png)\n",
    "\n",
    "Рассмотрим один блок поближе:\n",
    "\n",
    "![lstm](img/understanding_lstms.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.linear_f = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.linear_u = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.linear_c = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.linear_o = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        \n",
    "        self.i2o = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, c_prev, h_prev, x):\n",
    "        combined = torch.cat([x, h_prev], 1)\n",
    "        f = torch.sigmoid(self.linear_f(combined))\n",
    "        u = torch.sigmoid(self.linear_u(combined))\n",
    "        c_tilde = torch.tanh(self.linear_c(combined))\n",
    "        c = f*c_prev + u*c_tilde\n",
    "        o = torch.sigmoid(self.linear_o(combined))\n",
    "        h = o*torch.tanh(c)\n",
    "        y = self.i2o(h)\n",
    "        \n",
    "        return c, h, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(trn_ds.vocab_size, hidden_size, trn_ds.vocab_size).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        c_prev = torch.zeros([1, hidden_size], dtype=torch.float, device=device)\n",
    "        h_prev = torch.zeros_like(c_prev)\n",
    "        idx = random.randint(1, 26)\n",
    "        x = c_prev.new_zeros([1, trn_ds.vocab_size])\n",
    "        x[0, idx] = 1\n",
    "        sampled_indexes = [idx]\n",
    "        n_chars = 1\n",
    "        newline_char_idx = trn_ds.ch_to_idx['\\n']\n",
    "        while n_chars != 50 and idx != newline_char_idx:\n",
    "            c_prev, h_prev, y_pred = model(c_prev, h_prev, x)\n",
    "            \n",
    "            np.random.seed(np.random.randint(1, 5000))\n",
    "            idx = np.random.choice(np.arange(trn_ds.vocab_size), p=torch.softmax(y_pred, 1).cpu().numpy().ravel())\n",
    "            sampled_indexes.append(idx)\n",
    "            \n",
    "            x = (y_pred == y_pred.max(1)[0]).float()\n",
    "            \n",
    "            n_chars += 1\n",
    "            \n",
    "            if n_chars == 50:\n",
    "                sampled_indexes.append(newline_char_idx)\n",
    "                \n",
    "    model.train()\n",
    "    return sampled_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    for line_num, (x, y) in enumerate(trn_dl):\n",
    "        loss = 0\n",
    "        optimizer.zero_grad()\n",
    "        c_prev = torch.zeros([1, hidden_size], dtype=torch.float, device=device)\n",
    "        h_prev = torch.zeros_like(c_prev)\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        for i in range(x.shape[1]):\n",
    "            c_prev, h_prev, y_pred = model(c_prev, h_prev, x[:, i])\n",
    "            loss += loss_fn(y_pred, y[:, i])\n",
    "            \n",
    "        if (line_num+1) % 100 == 0:\n",
    "            print_sample(sample(model))\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, loss_fn, optimizer, epochs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание №3\n",
    "Написать функцию ```get_prob()```, оценивающую веростность порождения одной строки (из файла) и найти самую вероятную строку, порождаемую каждой из трех языковых моделей.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Источники\n",
    "\n",
    "1. [Динозавры – 1](https://github.com/furkanu/deeplearning.ai-pytorch/tree/master/5-%20Sequence%20Models/Week%201/Dinosaur%20Island%20--%20Character-level%20language%20model)\n",
    "2. [Динозавры – 2](https://github.com/Kulbear/deep-learning-coursera/blob/master/Sequence%20Models/Dinosaurus%20Island%20--%20Character%20level%20language%20model%20final%20-%20v3.ipynb)\n",
    "3. [Статья, объясняющая LSTM](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
